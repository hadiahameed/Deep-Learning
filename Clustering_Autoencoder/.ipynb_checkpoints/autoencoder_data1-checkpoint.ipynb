{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "x_data = pd.read_csv(\"data1.csv\")\n",
    "x_data = x_data.dropna()\n",
    "x_data = x_data.astype('float32')\n",
    "norm2 = normalize(x_data, axis=0)\n",
    "y_data = x_data['Class']\n",
    "y_data = y_data.astype(int)\n",
    "x_data.drop(['Class'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=0, stratify=y_data)\n",
    "\n",
    "x_data = x_data.values\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 2 \n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(28,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(28, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227845 samples, validate on 56962 samples\n",
      "Epoch 1/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.1180 - val_loss: 1.0632\n",
      "Epoch 2/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0431 - val_loss: 1.0424\n",
      "Epoch 3/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0261 - val_loss: 1.0297\n",
      "Epoch 4/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0178 - val_loss: 1.0243\n",
      "Epoch 5/20\n",
      "227845/227845 [==============================] - 1s 5us/step - loss: 1.0137 - val_loss: 1.0213\n",
      "Epoch 6/20\n",
      "227845/227845 [==============================] - 1s 5us/step - loss: 1.0114 - val_loss: 1.0193\n",
      "Epoch 7/20\n",
      "227845/227845 [==============================] - 1s 5us/step - loss: 1.0096 - val_loss: 1.0176\n",
      "Epoch 8/20\n",
      "227845/227845 [==============================] - 1s 5us/step - loss: 1.0081 - val_loss: 1.0162\n",
      "Epoch 9/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0068 - val_loss: 1.0149\n",
      "Epoch 10/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0056 - val_loss: 1.0139\n",
      "Epoch 11/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0045 - val_loss: 1.0125\n",
      "Epoch 12/20\n",
      "227845/227845 [==============================] - 1s 5us/step - loss: 1.0035 - val_loss: 1.0117\n",
      "Epoch 13/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0028 - val_loss: 1.0111\n",
      "Epoch 14/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0023 - val_loss: 1.0106\n",
      "Epoch 15/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0018 - val_loss: 1.0103\n",
      "Epoch 16/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0014 - val_loss: 1.0099\n",
      "Epoch 17/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0010 - val_loss: 1.0096\n",
      "Epoch 18/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0007 - val_loss: 1.0093\n",
      "Epoch 19/20\n",
      "227845/227845 [==============================] - 1s 5us/step - loss: 1.0004 - val_loss: 1.0090\n",
      "Epoch 20/20\n",
      "227845/227845 [==============================] - 1s 6us/step - loss: 1.0002 - val_loss: 1.0088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a14e0fda0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=20,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(7, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(7, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Top ten reconstruction errors')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = autoencoder.predict(x_test)\n",
    "mse = np.mean(np.power(x_test - predictions, 2), axis=1)\n",
    "\n",
    "sorted_mag = np.sort(-mse, axis=0)\n",
    "sorted_mag = sorted_mag.astype(int)\n",
    "\n",
    "sorted_mag = -sorted_mag[0:10]\n",
    "x = np.arange(1,11,1)\n",
    "plt.bar(x,sorted_mag,align='center')\n",
    "plt.xticks(x, x)\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.xlabel('Index')\n",
    "plt.title('Top ten reconstruction errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_data)\n",
    "i = np.where(y_data == 1)\n",
    "x_1 = encoded_imgs[i,0]\n",
    "y_1 = encoded_imgs[i,1]\n",
    "i = np.where(y_data == 0)\n",
    "x_0 = encoded_imgs[i,0]\n",
    "y_0 = encoded_imgs[i,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_1, y_1,color='red', alpha=1)\n",
    "plt.scatter(x_0, y_0,color='blue', alpha=0.09)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(['Class 1','Class 0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(y_test == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "x_data = pd.read_csv(\"data1.csv\")\n",
    "x_data = x_data.dropna()\n",
    "x_data = x_data.astype('float32')\n",
    "norm2 = normalize(x_data, axis=0)\n",
    "y_data = x_data['Class']\n",
    "y_data = y_data.astype(int)\n",
    "x_data.drop(['Class'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=0, stratify=y_data)\n",
    "\n",
    "x_data = x_data.values\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "encoding_dim = 2 \n",
    "input_img = Input(shape=(x_train.shape[1],))\n",
    "encoded = Dense(56, activation='relu')(input_img)\n",
    "encoded = Dense(28, activation='relu')(encoded)\n",
    "encoded = Dense(14, activation='relu')(encoded)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "\n",
    "decoded = Dense(14, activation='relu')(encoded)\n",
    "decoded = Dense(28, activation='relu')(decoded)\n",
    "decoded = Dense(56, activation='relu')(decoded)\n",
    "decoded = Dense(28, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer1 = autoencoder.layers[-4]\n",
    "decoder_layer2 = autoencoder.layers[-3]\n",
    "decoder_layer3 = autoencoder.layers[-2]\n",
    "decoder_layer4 = autoencoder.layers[-1]\n",
    "\n",
    "decoder = Model(encoded_input,  ( decoder_layer4(decoder_layer3( decoder_layer2(decoder_layer1(encoded_input)) ))  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=20,\n",
    "                batch_size=200,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(7, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(7, 4))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(x_test)\n",
    "mse = np.mean(np.power(x_test - predictions, 2), axis=1)\n",
    "\n",
    "sorted_mag = np.sort(-mse, axis=0)\n",
    "sorted_mag = sorted_mag.astype(int)\n",
    "\n",
    "sorted_mag = -sorted_mag[0:10]\n",
    "x = np.arange(1,11,1)\n",
    "plt.bar(x,sorted_mag,align='center')\n",
    "plt.xticks(x, x)\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.xlabel('Index')\n",
    "plt.title('Top ten reconstruction errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_data)\n",
    "i = np.where(y_data == 1)\n",
    "x_1 = encoded_imgs[i,0]\n",
    "y_1 = encoded_imgs[i,1]\n",
    "i = np.where(y_data == 0)\n",
    "x_0 = encoded_imgs[i,0]\n",
    "y_0 = encoded_imgs[i,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_1, y_1,color='red', alpha=1)\n",
    "plt.scatter(x_0, y_0,color='blue', alpha=0.09)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(['Class 1','Class 0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
